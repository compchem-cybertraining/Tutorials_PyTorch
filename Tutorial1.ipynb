{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68d5523-f561-4a04-bdc6-3e6ce12ce428",
   "metadata": {},
   "source": [
    "# Tutorial 1\n",
    "\n",
    "In this notebook, I summarize different small examples to clarify the tricky points of PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97fe8a12-fc3a-4737-a489-4167834d6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbca97-9780-4ec0-a5b8-4ac252089579",
   "metadata": {},
   "source": [
    "TOC \n",
    "\n",
    "1. Shape changing\n",
    "\n",
    "   - 1.1. The `unsqeeze` function\n",
    "   - 1.2. Shape change for broadcasting operations\n",
    "   - 1.3. Stacking tensors\n",
    "   - 1.4. Concatenating tensors\n",
    "   - 1.5. Slicing operations\n",
    "   - 1.6. Permuting tensors\n",
    "  \n",
    "2. Basic operations\n",
    "\n",
    "   - 2.1. Batch arithmetics\n",
    "   - 2.2. Einsum notation\n",
    "   - 2.3. Broadcasting matrix calculations\n",
    "   \n",
    "3. Automatic differentiation\n",
    "\n",
    "   - 3.1. Simple 1D example\n",
    "   - 3.2. 2D example\n",
    "   - 3.3. More interesting case\n",
    "   - 3.4. Computing Hessian\n",
    "\n",
    "4. Misc functions\n",
    "\n",
    "   - 4.1. Safely extract the key-value pairs from dictionaries\n",
    "   - 4.2. Generating tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912eb70-5f5e-4e16-b00a-194463fae812",
   "metadata": {},
   "source": [
    "## 1. Shape changing\n",
    "\n",
    "### 1.1. The `unsqeeze` function\n",
    "\n",
    "Here is how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9251b33f-3911-43c7-83a2-783a0e865f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1, 2, 3])\n",
      "Shape: torch.Size([3])\n",
      "unsqueeze(x, 0): tensor([[1, 2, 3]])\n",
      "Shape: torch.Size([1, 3])\n",
      "unsqueeze(x, 1): tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "Shape: torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(\"Original tensor:\", x)\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "# Use unsqueeze to add a dimension at position 0\n",
    "x_unsqueeze_0 = torch.unsqueeze(x, 0)\n",
    "print(\"unsqueeze(x, 0):\", x_unsqueeze_0)\n",
    "print(\"Shape:\", x_unsqueeze_0.shape)\n",
    "\n",
    "# Use unsqueeze to add a dimension at position 1\n",
    "x_unsqueeze_1 = torch.unsqueeze(x, 1)\n",
    "print(\"unsqueeze(x, 1):\", x_unsqueeze_1)\n",
    "print(\"Shape:\", x_unsqueeze_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6495a65-6077-49f0-b50d-2b2964193a58",
   "metadata": {},
   "source": [
    "### 1.2. Shape change for broadcasting operations\n",
    "\n",
    "Consider two tensors, of different rank (shape). It is not possible to divide one by the other becasue the \n",
    "number of elements in the far-most dimension (axes) is different for the two tensors. For A is it 4 (for the axis = 2)\n",
    "and for the tenor B it is 4 (axis = 0). Since the alignment of operations happens in the far-most dimensions first,\n",
    "this won't work. Moreover, this is not what we actually want. We do want to align the axis = 0 of the tensor B with the \n",
    "axis = 0 of the tensor A and do the broadcasting for the remaining dimensions. \n",
    "\n",
    "To do this, we need to change the shape of the tensor B to match that of the A. In doing so, the dimensions for which the \n",
    "broadcasting will be done will have size of one (so-called singletons). \n",
    "\n",
    "Here are several ways of how to do it:\n",
    "\n",
    "* Using `None`\n",
    "\n",
    "* Using `unsqueeze(-1)` to expand in the last dimension. We do this repetitively.\n",
    "\n",
    "* Using `unsquieeze(n)` to expand along the dimension n. We do this twice, but with different numbers.\n",
    "\n",
    "* Using `view` to explicitly reshape the tensor to the expected shape. In the first form, we explicitly\n",
    "\n",
    "  define the sizes along each axis. In the second form, we first create suitable tuple and pass it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227788aa-5f23-4932-b9b9-2464d2c7f245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.8173,  1.7630, -0.9214,  0.6545],\n",
      "         [ 0.4654, -0.0473,  0.4240,  0.1103],\n",
      "         [ 0.0247, -0.9844, -0.7084,  0.8355],\n",
      "         [-0.5720,  0.0171, -1.1509,  1.2556]],\n",
      "\n",
      "        [[-0.6683, -1.7170, -0.6805, -1.7154],\n",
      "         [-0.5060, -1.0532, -1.6286,  1.2230],\n",
      "         [ 1.5697, -0.6841,  0.4466,  0.7155],\n",
      "         [-0.1470, -0.3523, -0.4768, -0.2535]]])\n",
      "tensor([2., 4.])\n",
      "=====Case 1=======\n",
      "tensor([[[-0.9086,  0.8815, -0.4607,  0.3272],\n",
      "         [ 0.2327, -0.0236,  0.2120,  0.0552],\n",
      "         [ 0.0123, -0.4922, -0.3542,  0.4178],\n",
      "         [-0.2860,  0.0086, -0.5754,  0.6278]],\n",
      "\n",
      "        [[-0.1671, -0.4293, -0.1701, -0.4288],\n",
      "         [-0.1265, -0.2633, -0.4071,  0.3058],\n",
      "         [ 0.3924, -0.1710,  0.1117,  0.1789],\n",
      "         [-0.0367, -0.0881, -0.1192, -0.0634]]])\n",
      "=====Case 2=======\n",
      "tensor([[[-0.9086,  0.8815, -0.4607,  0.3272],\n",
      "         [ 0.2327, -0.0236,  0.2120,  0.0552],\n",
      "         [ 0.0123, -0.4922, -0.3542,  0.4178],\n",
      "         [-0.2860,  0.0086, -0.5754,  0.6278]],\n",
      "\n",
      "        [[-0.1671, -0.4293, -0.1701, -0.4288],\n",
      "         [-0.1265, -0.2633, -0.4071,  0.3058],\n",
      "         [ 0.3924, -0.1710,  0.1117,  0.1789],\n",
      "         [-0.0367, -0.0881, -0.1192, -0.0634]]])\n",
      "=====Case 3=======\n",
      "tensor([[[-0.9086,  0.8815, -0.4607,  0.3272],\n",
      "         [ 0.2327, -0.0236,  0.2120,  0.0552],\n",
      "         [ 0.0123, -0.4922, -0.3542,  0.4178],\n",
      "         [-0.2860,  0.0086, -0.5754,  0.6278]],\n",
      "\n",
      "        [[-0.1671, -0.4293, -0.1701, -0.4288],\n",
      "         [-0.1265, -0.2633, -0.4071,  0.3058],\n",
      "         [ 0.3924, -0.1710,  0.1117,  0.1789],\n",
      "         [-0.0367, -0.0881, -0.1192, -0.0634]]])\n",
      "=====Case 4=======\n",
      "tensor([[[-0.9086,  0.8815, -0.4607,  0.3272],\n",
      "         [ 0.2327, -0.0236,  0.2120,  0.0552],\n",
      "         [ 0.0123, -0.4922, -0.3542,  0.4178],\n",
      "         [-0.2860,  0.0086, -0.5754,  0.6278]],\n",
      "\n",
      "        [[-0.1671, -0.4293, -0.1701, -0.4288],\n",
      "         [-0.1265, -0.2633, -0.4071,  0.3058],\n",
      "         [ 0.3924, -0.1710,  0.1117,  0.1789],\n",
      "         [-0.0367, -0.0881, -0.1192, -0.0634]]])\n",
      "=====Case 5=======\n",
      "tensor([[[-0.9086,  0.8815, -0.4607,  0.3272],\n",
      "         [ 0.2327, -0.0236,  0.2120,  0.0552],\n",
      "         [ 0.0123, -0.4922, -0.3542,  0.4178],\n",
      "         [-0.2860,  0.0086, -0.5754,  0.6278]],\n",
      "\n",
      "        [[-0.1671, -0.4293, -0.1701, -0.4288],\n",
      "         [-0.1265, -0.2633, -0.4071,  0.3058],\n",
      "         [ 0.3924, -0.1710,  0.1117,  0.1789],\n",
      "         [-0.0367, -0.0881, -0.1192, -0.0634]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(2, 4, 4)      # shape [2, 4, 4]\n",
    "B = torch.tensor([2.0, 4.0])  # shape [2]\n",
    "\n",
    "print(A)\n",
    "print(B)\n",
    "\n",
    "print(\"=====Case 1=======\")\n",
    "C = A / B[:, None, None]      # shape [2, 4, 4]\n",
    "print(C)\n",
    "\n",
    "print(\"=====Case 2=======\")\n",
    "C = A/ B.unsqueeze(-1).unsqueeze(-1)\n",
    "print(C)\n",
    "\n",
    "print(\"=====Case 3=======\")\n",
    "C = A/ B.unsqueeze(1).unsqueeze(2)\n",
    "print(C)\n",
    "\n",
    "print(\"=====Case 4=======\")\n",
    "C = A/B.view(2,1,1)\n",
    "print(C)\n",
    "\n",
    "x = [2]; x.extend([1 for _ in range(2)])\n",
    "x = tuple(x)\n",
    "print(\"=====Case 5=======\")\n",
    "C = A/B.view(x)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcad4fc-f7eb-43b7-92d4-f6811ff52bad",
   "metadata": {},
   "source": [
    "Analogously, we can use the `reshape` function:\n",
    "\n",
    "* It returns a new tensor and doesn't affect the original one\n",
    "\n",
    "* Use `-1` to automatically determine the size of the missing dmensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d182052-2fa6-4c5e-a8a8-33ddcec360b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[[0.1093, 0.5209],\n",
      "         [0.1620, 0.1344]],\n",
      "\n",
      "        [[0.9223, 0.9554],\n",
      "         [0.6976, 0.6609]]]) torch.Size([2, 2, 2])\n",
      "z = tensor([[[0.1093],\n",
      "         [0.5209]],\n",
      "\n",
      "        [[0.1620],\n",
      "         [0.1344]],\n",
      "\n",
      "        [[0.9223],\n",
      "         [0.9554]],\n",
      "\n",
      "        [[0.6976],\n",
      "         [0.6609]]]) torch.Size([4, 2, 1])\n",
      "x = tensor([[[0.1093, 0.5209],\n",
      "         [0.1620, 0.1344]],\n",
      "\n",
      "        [[0.9223, 0.9554],\n",
      "         [0.6976, 0.6609]]]) torch.Size([2, 2, 2])\n",
      "z = tensor([[[0.1093]],\n",
      "\n",
      "        [[0.5209]],\n",
      "\n",
      "        [[0.1620]],\n",
      "\n",
      "        [[0.1344]],\n",
      "\n",
      "        [[0.9223]],\n",
      "\n",
      "        [[0.9554]],\n",
      "\n",
      "        [[0.6976]],\n",
      "\n",
      "        [[0.6609]]]) torch.Size([8, 1, 1])\n",
      "z = tensor([[[0.1093, 0.5209, 0.1620, 0.1344, 0.9223, 0.9554, 0.6976, 0.6609]]]) torch.Size([1, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2, 2)\n",
    "print(\"x =\", x, x.shape)\n",
    "\n",
    "z = x.reshape( 4, 2, 1 )\n",
    "print(\"z =\", z, z.shape)\n",
    "print(\"x =\", x, x.shape)\n",
    "\n",
    "z = x.reshape(8,1,-1)\n",
    "print(\"z =\", z, z.shape)\n",
    "\n",
    "z = x.reshape(-1,1,8)\n",
    "print(\"z =\", z, z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a72f28-c2d3-45fc-b951-6f9588838d8e",
   "metadata": {},
   "source": [
    "We can expand the tensor along multiple axes in the following ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83593c4-0252-4e52-85be-08330914c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z =  tensor([[[[[[0.1093]]],\n",
      "\n",
      "\n",
      "          [[[0.5209]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.1620]]],\n",
      "\n",
      "\n",
      "          [[[0.1344]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[0.9223]]],\n",
      "\n",
      "\n",
      "          [[[0.9554]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[0.6976]]],\n",
      "\n",
      "\n",
      "          [[[0.6609]]]]]]) torch.Size([2, 2, 2, 1, 1, 1])\n",
      "z =  tensor([[[[0.1093],\n",
      "          [0.5209]],\n",
      "\n",
      "         [[0.1620],\n",
      "          [0.1344]]],\n",
      "\n",
      "\n",
      "        [[[0.9223],\n",
      "          [0.9554]],\n",
      "\n",
      "         [[0.6976],\n",
      "          [0.6609]]]]) torch.Size([2, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "z = x.reshape(2,2,2,*[1]*3)\n",
    "print(\"z = \", z, z.shape)\n",
    "\n",
    "z = x.reshape(2,2,2,-1)\n",
    "print(\"z = \", z, z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f54a0e-db6e-4fef-a20c-7bc5b1966d7b",
   "metadata": {},
   "source": [
    "### 1.3. Stacking tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e2429e-1d75-4ce1-b847-013902eeb230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3352, 0.4766],\n",
      "        [0.5680, 0.5764]])\n",
      "torch.Size([2, 2])\n",
      "tensor([[[0.3352, 0.4766],\n",
      "         [0.5680, 0.5764]],\n",
      "\n",
      "        [[0.3352, 0.4766],\n",
      "         [0.5680, 0.5764]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand([2,2])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "b = torch.stack([a,a])\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a4652-c390-4ab7-88db-c7140d7ecc97",
   "metadata": {},
   "source": [
    "### 1.4. Concatenating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fb1c91-1981-4621-9301-38fa482148c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3205, 0.3908],\n",
      "        [0.4805, 0.2954]])\n",
      "torch.Size([2, 2])\n",
      "tensor([[0.3205, 0.3908],\n",
      "        [0.4805, 0.2954],\n",
      "        [0.3205, 0.3908],\n",
      "        [0.4805, 0.2954]])\n",
      "torch.Size([4, 2])\n",
      "tensor([[0.3205, 0.3908, 0.3205, 0.3908],\n",
      "        [0.4805, 0.2954, 0.4805, 0.2954]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand([2,2])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "b = torch.cat([a,a], dim=0)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "c = torch.cat([a,a], dim=1)\n",
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366623c-05dc-419f-b95a-aa440741dfb9",
   "metadata": {},
   "source": [
    "### 1.5. Slicing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f9e032-dc9c-49be-b353-486c766b4d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1.],\n",
      "         [2., 3.]],\n",
      "\n",
      "        [[4., 5.],\n",
      "         [6., 7.]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,2,2)\n",
    "cnt = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            a[i,j,k] = cnt\n",
    "            cnt += 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d74fc-bc8d-4536-bfc5-ba2bef96af6c",
   "metadata": {},
   "source": [
    "Slicing left-to-right works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc9898d3-d178-45ba-8920-371798dec01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(a[0])\n",
    "print(a[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154a1947-13b0-45db-8e8f-033c0944f7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1.])\n",
      "tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(a[0,0])\n",
    "print(a[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc7afcd-6a2d-472f-932c-2fd97f200a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(a[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589380f1-e3d2-431f-8f33-adf54d3def63",
   "metadata": {},
   "source": [
    "But going the other way is not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9a80fc-537a-4913-b4ef-42d68fc9f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [4., 5.]])\n",
      "tensor([[0., 2.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(a[:, 0])\n",
    "print(a[:, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542d301-3a2f-427f-a835-d4becec0840e",
   "metadata": {},
   "source": [
    "Let’s assume:\n",
    "\n",
    "```a.shape == (nbatch, ntraj, ndof)  # 3D tensor```\n",
    "\n",
    "✅ a[:, 0]\n",
    "\n",
    "    Means: Take all nbatch, pick ntraj=0, keep all ndof\n",
    "\n",
    "    Result shape: (nbatch, ndof)\n",
    "\n",
    "✅ a[:, :, 0]\n",
    "\n",
    "    Means: Take all nbatch, all ntraj, pick ndof=0\n",
    "\n",
    "    Result shape: (nbatch, ntraj)\n",
    "\n",
    "The correct way to extract what we need would be this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6fc740-b1d2-4729-9c95-ea7d9e083fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1.],\n",
      "         [2., 3.]],\n",
      "\n",
      "        [[4., 5.],\n",
      "         [6., 7.]]])\n",
      "tensor([[0., 2.],\n",
      "        [4., 6.]])\n",
      "tensor([0., 4.])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a[..., 0])\n",
    "print(a[..., 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d23a38-0154-41d5-9639-09c107773e99",
   "metadata": {},
   "source": [
    "### 1.6. Permuting tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360deb8e-a42d-41d8-95c4-247004e2a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[[0.0868, 0.0858, 0.0277],\n",
      "         [0.8058, 0.9812, 0.5894]]]) torch.Size([1, 2, 3])\n",
      "identity permutation =  tensor([[[0.0868, 0.0858, 0.0277],\n",
      "         [0.8058, 0.9812, 0.5894]]]) torch.Size([1, 2, 3])\n",
      "0->0, 1->2, 2->1 permutation =  tensor([[[0.0868, 0.8058],\n",
      "         [0.0858, 0.9812],\n",
      "         [0.0277, 0.5894]]]) torch.Size([1, 3, 2])\n",
      "0->1, 1->0, 2->2 permutation =  tensor([[[0.0868, 0.0858, 0.0277]],\n",
      "\n",
      "        [[0.8058, 0.9812, 0.5894]]]) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 2, 3)\n",
    "print(\"x = \", x, x.shape)\n",
    "\n",
    "y = x.permute(0, 1, 2)\n",
    "print(\"identity permutation = \", y, y.shape)\n",
    "\n",
    "y = x.permute(0, 2, 1)\n",
    "print(\"0->0, 1->2, 2->1 permutation = \", y, y.shape)\n",
    "\n",
    "y = x.permute(1, 0, 2)\n",
    "print(\"0->1, 1->0, 2->2 permutation = \", y, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b1365-f4fb-4e4b-8d66-14ede2a92a26",
   "metadata": {},
   "source": [
    "## 2. Basic operations\n",
    "\n",
    "### 2.1. Batch arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b9c5841-a89b-43d9-9cdf-6d124c510c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]) tensor([0., 0.])\n",
      "torch.Size([3, 2])\n",
      "tensor([[ 1., -1.],\n",
      "        [ 0.,  1.],\n",
      "        [ 2.,  0.]]) tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,2)  # 3 trajectories with 2 DOFs\n",
    "b = torch.zeros(2)    # 1 point with 2 DOF\n",
    "\n",
    "print(a, b)\n",
    "a[0,0], a[0,1] = 1, -1  # 0-th traj \n",
    "a[1,0], a[1,1] = 0,  1  # 1-st traj\n",
    "a[2,0], a[2,1] = 2,  0  # 2-nd traj\n",
    "print(a.shape)\n",
    "\n",
    "b[0], b[1] = 0, 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4a6ea8b-07c2-4beb-9096-4c10d6da1d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -3.],\n",
      "        [ 0., -1.],\n",
      "        [ 2., -2.]])\n"
     ]
    }
   ],
   "source": [
    "print(a - 2*b)   # repeat for each trajectory (dimension 0 is broadcasted, since the alignment\n",
    "                 # is done for the far-most dimensions (axis = 1 for a and axis = 0 for b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85be80-3a66-44eb-9ecb-3600b1742dd9",
   "metadata": {},
   "source": [
    "One can explicitly change the shape of b with the `view` function to make it consistent in shape with `a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be124d6f-0c74-4869-8653-92fae2a16b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.]])\n",
      "tensor([[ 1., -3.],\n",
      "        [ 0., -1.],\n",
      "        [ 2., -2.]])\n"
     ]
    }
   ],
   "source": [
    "print(b.view(1,2))\n",
    "print(a - 2*b.view(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415f98c-d4b0-4349-b330-5b4f4ace4fd9",
   "metadata": {},
   "source": [
    "But in this case, we are fine since the broadcasting works well.\n",
    "\n",
    "So, for instance, we can also square all the elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3fb027-dc66-4d4e-9f68-2d092d12d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 9.],\n",
      "        [0., 1.],\n",
      "        [4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print( (a - 2*b)**2 )  # repeat for each trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cc379-d4d7-4bc5-b875-c71b34dda545",
   "metadata": {},
   "source": [
    "Now, we can compute producs or sums along different axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "794de9ba-17d1-4c41-883d-7356a59ad942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "tensor([[ 9.],\n",
      "        [ 0.],\n",
      "        [16.]])\n"
     ]
    }
   ],
   "source": [
    "prd = torch.prod( (a - 2*b)**2, 1,  True) # product over all DOFs, keep dimension\n",
    "print( prd.shape )\n",
    "print( prd )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3df60f62-c3e8-4481-ab03-4ca9ed23d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([ 9.,  0., 16.])\n"
     ]
    }
   ],
   "source": [
    "prd = torch.prod( (a - 2*b)**2, 1,  False)  # product over all DOFs\n",
    "                                            # Here, we don't keep dimension, so the \n",
    "                                            # rank of the resulting tensor is reduced\n",
    "print(prd.shape)\n",
    "print(prd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8203c-6044-4b87-901d-c27be84eef2d",
   "metadata": {},
   "source": [
    "Likewise, we can do a summation over different axes while keeping the dimension or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc78d45-ce1e-425e-825b-7d35db615582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[ 1., -1.],\n",
      "        [ 0.,  1.],\n",
      "        [ 2.,  0.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "tensor([[3., 0.]])\n",
      "tensor([[3., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "print(a.sum(1, True))\n",
    "print(torch.sum(a, 1, True))\n",
    "\n",
    "print(a.sum(0, True))\n",
    "print(torch.sum(a, 0, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe0af19-128c-4835-8146-a84f026d7faa",
   "metadata": {},
   "source": [
    "Or a slightly more complicated result, but more useful in the computational chemistry context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7da6ba69-ab72-4aa7-b409-6cbafda88a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.)\n"
     ]
    }
   ],
   "source": [
    "print (torch.sum(torch.prod( (a - 2*b)**2, 1,  False) ) )  # reduce dimension and sum over all trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40eeeb-43e3-43c3-a2d4-bb16fdb4efa7",
   "metadata": {},
   "source": [
    "### 2.2. Einsum notation\n",
    "\n",
    "Consider 4 points with 2-dimensional vectors.\n",
    "\n",
    "Let's say for each point we want to compute the outer products of the corresponding vectors (so 2 x 2 matrix).\n",
    "\n",
    "It is very convenient to use the ellipses `...` notaton for the dimensions we don't care, but we want to \n",
    "broadcast to\n",
    "\n",
    "This can be done this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "794aba12-209a-4519-a333-18da902b7cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "outer =  tensor([[[ 1.,  1.],\n",
      "         [ 1.,  1.]],\n",
      "\n",
      "        [[ 1., -2.],\n",
      "         [-2.,  4.]],\n",
      "\n",
      "        [[ 1.,  0.],\n",
      "         [ 0.,  0.]],\n",
      "\n",
      "        [[ 1., -0.],\n",
      "         [-0.,  0.]]]) torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "psi = torch.tensor([ [1.0, 1.0], \n",
    "                      [-1.0, 2.0], \n",
    "                      [1.0, 0.0], \n",
    "                      [-1.0, 0.0] ])\n",
    "print(psi.shape)\n",
    "\n",
    "outer = torch.einsum(\"...i, ...j -> ...ij\", psi, psi)\n",
    "\n",
    "print(\"outer = \", outer, outer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021639e5-aa0f-4507-af1d-f06fdc86b070",
   "metadata": {},
   "source": [
    "or we could have reshaped the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cad0e93-4734-4328-a57d-c295eabd438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.,  1., -1.],\n",
      "        [ 1.,  2.,  0.,  0.]]) torch.Size([2, 4])\n",
      "outer =  tensor([[[ 1.,  1.,  1.,  1.],\n",
      "         [ 1., -2.,  0., -0.]],\n",
      "\n",
      "        [[ 1., -2.,  0., -0.],\n",
      "         [ 1.,  4.,  0.,  0.]]]) torch.Size([2, 2, 4])\n",
      "outer2 =  tensor([[[ 1.,  1.],\n",
      "         [ 1.,  1.]],\n",
      "\n",
      "        [[ 1., -2.],\n",
      "         [-2.,  4.]],\n",
      "\n",
      "        [[ 1.,  0.],\n",
      "         [ 0.,  0.]],\n",
      "\n",
      "        [[ 1., -0.],\n",
      "         [-0.,  0.]]]) torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "psi2 = psi.permute(1,0)\n",
    "print(psi2, psi2.shape)\n",
    "\n",
    "outer = torch.einsum(\"i..., j... -> ij...\", psi2, psi2)\n",
    "print(\"outer = \", outer, outer.shape)\n",
    "\n",
    "outer2 = outer.permute(2, 0, 1)\n",
    "print(\"outer2 = \", outer2, outer2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05a296-e675-4f43-959f-7333d69830ce",
   "metadata": {},
   "source": [
    "### 2.3. Broadcasting matrix operations\n",
    "\n",
    "In this example, we have 3 grid points, each containing 1 degree of freedom, so the input is a 3 x 1 tensor.\n",
    "\n",
    "We want to compute a 2 x 2 matrix for each of the point such that the diagonal elements of the matrix are set to\n",
    "the value and the squared value of the first component of the corresponding point.\n",
    "\n",
    "Here, we use the ellipse `...` notation to refer to any possible dimensions not explicitly considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "251887b1-1e64-403e-bc74-0098d11831c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  torch.Size([3, 1])\n",
      "v.shape =  torch.Size([3, 2, 2])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[2., 0.],\n",
      "         [0., 4.]],\n",
      "\n",
      "        [[3., 0.],\n",
      "         [0., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "def x2(x):\n",
    "    # x[npoints, ndims]\n",
    "    print(\"x.shape = \", x.shape)\n",
    "    v = torch.zeros((*x.shape[:-1], 2, 2), dtype=torch.float)\n",
    "    print(\"v.shape = \", v.shape)\n",
    "    v[..., 0, 0] = x[..., 0]; \n",
    "    v[..., 1, 1] = x[..., 0]**2\n",
    "    return v\n",
    "\n",
    "q = torch.tensor([ [1], [2], [3] ])\n",
    "\n",
    "Vmat = x2(q)\n",
    "\n",
    "print(q)\n",
    "print(Vmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244644a-bca9-42fe-9738-22755c1aee77",
   "metadata": {},
   "source": [
    "## 3. Automatic differentiation\n",
    "\n",
    "### 3.1. Simple 1D example\n",
    "\n",
    "Here, we compute the derivative of the quadratic function:\n",
    "\n",
    "$$ \\frac{d}{dx} x^2 = 2 x $$\n",
    "\n",
    "and use this derivative to advance the $x$ variable.\n",
    "\n",
    "Note:\n",
    "* the function that we use to generate the tensor that will be differentiated later should retern a \"scalar\" (single value)\n",
    "  \n",
    "* if we want to differentiate wrt `x` variable, it should have the`requires_grad=True` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c2d57e6-e319-41f3-9352-cd6ac6c46dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True) tensor(1., grad_fn=<SumBackward0>) tensor([2.])\n",
      "tensor([3.], grad_fn=<AddBackward0>) tensor(9., grad_fn=<SumBackward0>) tensor([6.])\n",
      "tensor([9.], grad_fn=<AddBackward0>) tensor(81., grad_fn=<SumBackward0>) tensor([18.])\n"
     ]
    }
   ],
   "source": [
    "def mysq(x):\n",
    "    return torch.sum(x**2)\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "for i in range(3):\n",
    "    y = mysq(x)\n",
    "    [z] = torch.autograd.grad(y, x)\n",
    "    print(x, y, z)\n",
    "    x = x + z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855a637-ec3b-4037-8459-068804c77749",
   "metadata": {},
   "source": [
    "### 3.2. 2D example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9930e0bb-319c-47e3-a714-8fd5d4031bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n",
      "tensor([-1.], requires_grad=True)\n",
      "tensor(2., grad_fn=<SumBackward0>)\n",
      "tensor([2.])\n",
      "tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "def mysq(x,y):\n",
    "    return torch.sum(x**2 + y**2)\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = torch.tensor([-1.0], requires_grad=True)\n",
    "\n",
    "f = mysq(x, y)\n",
    "[dfdx, dfdy] = torch.autograd.grad(f, [x, y])\n",
    "print(x)\n",
    "print(y)\n",
    "print(f)\n",
    "print(dfdx)\n",
    "print(dfdy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6f8da-827a-4b71-b915-0cff9fdc25c3",
   "metadata": {},
   "source": [
    "### 3.3. More interesting case\n",
    "\n",
    "Now, imagine we have a function that takes the `q` tensor with the last dimension representing \n",
    "different DOFs, e.g. `x = q[:, 0]` and y = `q[:, 1]`, for instance \n",
    "\n",
    "$$f = x^2 y$$\n",
    "\n",
    "$$\\frac{df}{dx} = 2 x y$$\n",
    "$$\\frac{df}{dy} = x^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fb973e7-7cad-4a34-8f4f-de1dd5a539f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func1(q):\n",
    "    # Note that we use the [...] operator to make it work for whatever number\n",
    "    # of dimensions we have beofre\n",
    "    return q[...,0]**2 * q[...,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0b6f6-8cd5-453f-ab6b-9a92782b2c8e",
   "metadata": {},
   "source": [
    "Now, let's say we need the derivatives of this function at a number of points (either for plotting PES or for different \n",
    "trajectories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e7dcab4-68b8-4e66-bb73-32c1f5ab30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.tensor([ [0.0, 0.5],\n",
    "                   [-1.0, 1.0],\n",
    "                   [2.0, -2.0],\n",
    "                  ], requires_grad=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb3e43-4862-4338-9779-14620b5f5899",
   "metadata": {},
   "source": [
    "Note that since the function returns a tensor for outer dimensions, we \n",
    "need to sum everything up first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c1095d3-043d-4b39-866a-602512a4b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.5000],\n",
      "        [-1.0000,  1.0000],\n",
      "        [ 2.0000, -2.0000]], requires_grad=True)\n",
      "tensor(-7., grad_fn=<SumBackward0>)\n",
      "tensor([[ 0.,  0.],\n",
      "        [-2.,  1.],\n",
      "        [-8.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.sum(my_func1(q))\n",
    "print(q)\n",
    "print(z)\n",
    "\n",
    "[der1] = torch.autograd.grad(z, [ q ]);\n",
    "print(der1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2eadb-e92c-40a9-b10c-8b50098021aa",
   "metadata": {},
   "source": [
    "But what if we have two batches of trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1784e8ab-6176-4de3-a750-a0d5fe7c5e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.5000],\n",
      "         [-1.0000,  1.0000],\n",
      "         [ 2.0000, -2.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.5000],\n",
      "         [-1.0000,  1.0000],\n",
      "         [ 2.0000, -2.0000]]], grad_fn=<StackBackward0>)\n",
      "tensor(-14., grad_fn=<SumBackward0>)\n",
      "tensor([[[ 0.,  0.],\n",
      "         [-2.,  1.],\n",
      "         [-8.,  4.]],\n",
      "\n",
      "        [[ 0.,  0.],\n",
      "         [-2.,  1.],\n",
      "         [-8.,  4.]]])\n"
     ]
    }
   ],
   "source": [
    "q2 = torch.stack([q,q])\n",
    "q2.shape\n",
    "print(q2)\n",
    "\n",
    "z2 = torch.sum(my_func1(q2))\n",
    "print(z2)\n",
    "\n",
    "[der1_2] = torch.autograd.grad(z2, [ q2 ]);\n",
    "print(der1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ebcc4a-7f65-44a3-a238-76dbda5e808b",
   "metadata": {},
   "source": [
    "### 3.4. Computing Hessian\n",
    "\n",
    "First, define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04e06c23-8496-484f-b27b-e4b570e6dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func2(q, params):\n",
    "    \"\"\"\n",
    "    q[..., itraj, idof]\n",
    "    k[idof]\n",
    "    q_min[idof]\n",
    "    \"\"\"\n",
    "    k, q_min = params[\"k\"], params[\"q_min\"]\n",
    "\n",
    "    ntraj, ndof = q.shape[-2], q.shape[-1]  # taking the last two dimensions\n",
    "    res = torch.zeros(())\n",
    "    for n in range(ntraj):\n",
    "        for i in range(ndof):\n",
    "            res = res + k[i] * (q[..., n, i] - q_min[i])**2 + k[i]**2 * q[..., n, i]**3 - k[i] * q[..., n, 0] * q[..., n, 1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d147d92-9d5c-4134-8970-4825d6b69ee0",
   "metadata": {},
   "source": [
    "Test the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d7dfb8a-9eb2-4c23-8818-6d294564dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5000, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "q = torch.tensor([ [0.0, 0.0],\n",
    "                   [1.0, 0.0],\n",
    "                   [-1.0, 1.0]\n",
    "                 ], requires_grad=True)\n",
    "q_min = torch.tensor( [ 0.0, 0.5] )\n",
    "k = torch.tensor( [1.0, 2.0])\n",
    "params = {\"k\":k, \"q_min\":q_min}\n",
    "\n",
    "f = my_func2(q, params)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b67b2-c88e-472b-9af7-049ca2426010",
   "metadata": {},
   "source": [
    "Now define the function to compute the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cdb3486-cdf7-4f27-8e87-d0cda0f62ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(q, function, function_params):\n",
    "    ntraj, ndof = q.shape[-2], q.shape[-1]\n",
    "\n",
    "    # Compute the function itself\n",
    "    f = function(q, function_params)\n",
    "\n",
    "    # Compute the first gradients\n",
    "    [grad] = torch.autograd.grad(f, q, create_graph=True)\n",
    "\n",
    "    return f, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf2261-cf30-4d2f-8344-fa65154b8c9f",
   "metadata": {},
   "source": [
    "And compute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2b22172-3c1d-4c00-8ceb-03990bd06217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.5000, grad_fn=<SubBackward0>)\n",
      "tensor([[ 0., -2.],\n",
      "        [ 5., -5.],\n",
      "        [-2., 17.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "f, grad = compute_derivatives(q, my_func2, params)\n",
    "\n",
    "print(f)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1dbf5-4925-4600-a32e-984ca39d6275",
   "metadata": {},
   "source": [
    "Now define the function to compute the Hessian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79d1bbc4-ec18-48b5-802a-dd388a3a21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives_hess(q, function, function_params):\n",
    "    ntraj, ndof = q.shape[-2], q.shape[-1]\n",
    "\n",
    "    # Compute the function itself\n",
    "    f = function(q, function_params)\n",
    "\n",
    "    # Compute the first gradients\n",
    "    [grad] = torch.autograd.grad(f, q, create_graph=True)\n",
    "    #print(grad.shape)\n",
    "\n",
    "    # Compute the second gradients\n",
    "    hess = torch.zeros( (ntraj, ndof, ndof) )\n",
    "    for k in range(ntraj):\n",
    "        for i in range(ndof):\n",
    "            [ d2f ] = torch.autograd.grad( grad[k, i], q, create_graph=True, retain_graph=True)\n",
    "            #print(d2f.shape)\n",
    "            hess[k, i, :] = d2f[k, :]\n",
    "\n",
    "    return f, grad, hess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f482d3-7bfc-414a-bb9a-6547eb13d632",
   "metadata": {},
   "source": [
    "Now compute all, including Hessian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e04e2edb-d8e2-4ddb-a9f2-d4ac3a45e34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f =  tensor(10.5000, grad_fn=<SubBackward0>)\n",
      "grad =  tensor([[ 0., -2.],\n",
      "        [ 5., -5.],\n",
      "        [-2., 17.]], grad_fn=<AddBackward0>)\n",
      "hess =  tensor([[[ 2., -3.],\n",
      "         [-3.,  4.]],\n",
      "\n",
      "        [[ 8., -3.],\n",
      "         [-3.,  4.]],\n",
      "\n",
      "        [[-4., -3.],\n",
      "         [-3., 28.]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "f, grad, hess = compute_derivatives_hess(q, my_func2, params)\n",
    "\n",
    "print(\"f = \", f)\n",
    "print(\"grad = \", grad)\n",
    "print(\"hess = \", hess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab3cbc-1c14-48c3-beb0-b183b93fbc60",
   "metadata": {},
   "source": [
    "**Exercise 1**: Generalize the above differentiation functions to the case of multiple batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855a891-411c-4f6b-b080-a4e567dfcd17",
   "metadata": {},
   "source": [
    "## 4. Misc functions\n",
    "\n",
    "### 4.1. Safely extract the key-value pairs from dictionaries\n",
    "\n",
    "If a keyword doesn't exist in the dictionary, trying to extract the corresponding value from the \n",
    "dictionary will lead to an error, so one can use the `get` function to define the default value.\n",
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a17473fa-1968-44f8-a573-f9534f502953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_vars(prms):\n",
    "    x = prms.get(\"x\", 2.0)\n",
    "    y = prms.get(\"y\", 0.0)\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9ee6b-f6be-486d-b930-a570cca16f11",
   "metadata": {},
   "source": [
    "As you can see below:\n",
    "- the value of the `x` variable is extracted from the input dictionary\n",
    "- the value of the `y` variable is not defined in the dictionary, so the default value is used\n",
    "\n",
    "Also, not that the input dictionary `prms` isn't modified by the `get` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02233ec6-eb39-40da-bade-96a9e9e4c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': -1.0}\n",
      "-1.0 0.0\n",
      "{'x': -1.0}\n"
     ]
    }
   ],
   "source": [
    "# Now use it\n",
    "prms = {\"x\":-1.0}\n",
    "print(prms)\n",
    "set_vars(prms)\n",
    "print(prms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b88d8-b3d0-4c68-9d1b-447a19560a75",
   "metadata": {},
   "source": [
    "### 4.2. Generating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d02eeae5-72a8-4ada-bcd5-ed3f31d3b2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2],\n",
       "        [-2],\n",
       "        [-2],\n",
       "        [-2],\n",
       "        [-2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[-2]]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f93431e0-346d-4517-b8f3-39b3c5ca84ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2],\n",
       "         [-2]],\n",
       "\n",
       "        [[-2],\n",
       "         [-2]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[[-2]]*2]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e59dc-d2fd-4af6-84d6-e053adb20a02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
